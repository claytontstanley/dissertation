does
anyone
have
,
or
know
of
,
a
binary
patch
generation
algorithm
implementation
in
c
#
?
basically
,
compare
two
file
(
designated
old
and
new
)
,
and
produce
a
patch
file
that
can
be
used
to
upgrade
the
old
file
to
have
the
same
content
a
the
new
file
.
the
implementation
would
have
to
be
relatively
fast
,
and
work
with
huge
file
.
it
should
exhibit
o
(
n
)
or
o
(
logn
)
runtimes
.
my
own
algorithm
tend
to
either
be
lousy
(
fast
but
produce
huge
patch
)
or
slow
(
produce
small
patch
but
have
o
(
n^2
)
runtime
)
.
any
advice
,
or
pointer
for
implementation
would
be
nice
.
specifically
,
the
implementation
will
be
used
to
keep
server
in
sync
for
various
large
datafiles
that
we
have
one
master
server
for
.
when
the
master
server
datafiles
change
,
we
need
to
update
several
off-site
server
a
well
.
the
most
naive
algorithm
i
have
made
,
which
only
work
for
file
that
can
be
kept
in
memory
,
is
a
follows
:
grab
the
first
four
byte
from
the
old
file
,
call
this
the
key
add
those
byte
to
a
dictionary
,
where
key
-
>
position
,
where
position
is
the
position
where
i
grabbed
those
4
byte
,
0
to
begin
with
skip
the
first
of
these
four
byte
,
grab
another
4
(
3
overlap
,
1
one
)
,
and
add
to
the
dictionary
the
same
way
repeat
step
1-3
for
all
4-byte
block
in
the
old
file
from
the
start
of
the
new
file
,
grab
4
byte
,
and
attempt
to
look
it
up
in
the
dictionary
if
found
,
find
the
longest
match
if
there
are
several
,
by
comparing
byte
from
the
two
file
encode
a
reference
to
that
location
in
the
old
file
,
and
skip
the
matched
block
in
the
new
file
if
not
found
,
encode
1
byte
from
the
new
file
,
and
skip
it
repeat
step
5-8
for
the
rest
of
the
new
file
this
is
somewhat
like
compression
,
without
windowing
,
so
it
will
use
a
lot
of
memory
.
it
is
,
however
,
fairly
fast
,
and
produce
quite
small
patch
,
a
long
a
i
try
to
make
the
code
output
minimal
.
a
more
memory-efficient
algorithm
us
windowing
,
but
produce
much
bigger
patch
file
.
there
are
more
nuance
to
the
above
algorithm
that
i
skipped
in
this
post
,
but
i
can
post
more
detail
if
necessary
.
i
do
,
however
,
feel
that
i
need
a
different
algorithm
altogether
,
so
improving
on
the
above
algorithm
is
probably
not
going
to
get
me
far
enough
.
edit
#
1
:
here
is
a
more
detailed
description
of
the
above
algorithm
.
first
,
combine
the
two
file
,
so
that
you
have
one
big
file
.
remember
the
cut-point
between
the
two
file
.
secondly
,
do
that
grab
4
byte
and
add
their
position
to
the
dictionary
step
for
everything
in
the
whole
file
.
thirdly
,
from
where
the
new
file
start
,
do
the
loop
with
attempting
to
locate
an
existing
combination
of
4
byte
,
and
find
the
longest
match
.
make
sure
we
only
consider
position
from
the
old
file
,
or
from
earlier
in
the
new
file
than
we
're
currently
at
.
this
ensures
that
we
can
reuse
material
in
both
the
old
and
the
new
file
during
patch
application
.
edit
#
2
:
source
code
to
the
above
algorithm
you
might
get
a
warning
about
the
certificate
having
some
problem
.
i
do
n't
know
how
to
resolve
that
so
for
the
time
being
just
accept
the
certificate
.
the
source
us
lot
of
other
type
from
the
rest
of
my
library
so
that
file
is
n't
all
it
take
,
but
that
's
the
algorithm
implementation
.