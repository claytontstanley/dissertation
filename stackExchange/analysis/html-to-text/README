To convert posts data to chunks:

[1] Export the Posts_Text_Subset view from Mysql Workbench to a csv file; name it in-huge.csv
	I'm not currently automating this, b/c I can't extract the exact sql code that is run
	for this to happen. Because the code through the workbench is more robust than the 
	automated solutions that I've found online.
[2] Run make convert to convert in-huge.csv to chunks-huge.csv
[3] Run make updateChunks to load chunks-huge.csv into MySQL 

To convert chunks data in mysql to R-readable sji and Bi csv files:

[1] call sotero.tag_priors("title-subset-*");
	* is the relevant training subset
	Save result to tag-priors-subset-*.csv in the ../model folder
	This csv contains the Bi priors
[2] call sotero.title_chunks("title-subset-*");
	* is same
	Save result to title-subset-*.csv in the ../model folder
	This csv contains the sji strength associations

File summaries:
subset-*:	Numbered subsets
		1: Training 100k
		2: Test 100k
		3: Temp 1k
		4: Training 1M
		5: Test 100k for subset-4
