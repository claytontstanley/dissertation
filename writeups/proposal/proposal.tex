\documentclass[man]{apa6}

\usepackage{textcomp}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}

%\usepackage[compact]{titlesec}

\usepackage{amssymb,amsmath}
\usepackage{setspace}

\usepackage[hyphens]{url}
%\usepackage{hyperref}
%\usepackage{breakurl}

\usepackage{graphicx}
\usepackage[group-separator={,}]{siunitx}
\RequirePackage[l2tabu, orthodox]{nag}
\graphicspath{{./figures/}} % Specifies the directory where pictures are stored

\usepackage{csquotes}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber,doi=false,uniquename=false]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{bibliography.bib}

% Needed to ensure periods are placed at the end of every bibliography entry in the references section
\AtEveryBibitem{\clearfield{doi}}

% Make sure only urls that are printed in references section are for webpages
\AtEveryBibitem{
  \ifentrytype{misc}{}{
    \clearfield{url}
  }
}

% ref: http://tex.stackexchange.com/questions/128592/remove-backslashes-from-url-fields-in-bib-entry
\DeclareSourcemap{
  \maps[datatype=bibtex]{
    \map{
      \step[fieldsource=url,
	match=\regexp{\\},
      replace=\regexp{}]
    }
  }
}


% If the toc is too detailed, try limiting the depth of printed sections in the TOC:
%\setcounter{tocdepth}{2}

\title{Psyc 601 Multivariate Statistics Project}
\shorttitle{Psyc 601 Project}

\author{Clayton Stanley}
\affiliation{Rice University}

\leftheader{Beitzel}

\abstract{
  The base StackOverflow tag-prediction model from the Fall '12 Psychometrics course was improved by incorporating the words in the body of the post and the post author's specific tagging history.
  We focused on hashtag creation as a specific human behavior, since understanding and modeling hashtag creation can lead to improved human-computer systems that can better identify users' goals and interests.
  We used multivariate logistic regression statistical techniques to guide the model building process, and found that adding the two model terms improved model accuracy from 56\% to 69\%.
  The model is a successful case showing that ACT-R's declarative memory retrieval equations scale, and are relevant to task domains that require large-scale knowledge stores.
}

\keywords{StackOverflow, Machine Learning, ACT-R, Tagging, Large-Scale Semantic Memory}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Motivation}

TODO: Motivation

Social media sites such as Twitter, Facebook, StackOverflow, Google+, and Yelp, are composed almost entirely of human-generated content.
The amount of human-generated content on these sites is staggering, and continues to grow.
Users of Twitter's microblogging service, for example, generate half a billion tweets per day \parencite{TwitterReport2012}.
However, a single user of a social media site is most likely interested in only a small fragment of this large amount of information.
One general question to support the the user in this domain is:
How can we quickly and effectively connect users to the content that they care about?

% FIXME: Fix cite for Bauer2012
One traditional technique is to provide the user with a powerful search engine so that they can actively look for content that interests them.
However, users are not forming the same search queries that work so effectively on search engines like Google.
Users of social media sites are searching for information that is happening now, in real time \cite{Bauer2012}.
In other words, users on social-media sites want the fresh \emph{stream} of information about a particular topic.
This can certainly be seen in the main user-interface views that these social media site provide:
Twitter's homepage showing your followers' tweets, Facebook's homepage showing your friends' posts, StackOverflow's daily digest of posts for particular tags, etc.

So how can we ensure that users are connected to the information streams that they care most about?
One promising approach is to model and predict the user's goals when using and searching these social media sites \parencite{Rose2004}.
If we have a better understanding of a user's goals, then we can tailor the information streams provided to the ones that are most inline with these goals.
For example, Twitter might suggest other users and hashtags for the user to follow, Facebook could suggest pages to like, Yelp could recommend businesses to check out, etc.
Researchers are currently looking for ways to automate the goal-identification task for more general search queries like those generated for Google \parencites{Jansen2008}{Lee2005}.

However, social media sites have an advantage for identifying user goals over traditional search engines:
Human-generated content.
Twitter does not have only the tweet that a user is currently composing to try and identify that user's goals.
Rather, the site has all of the user's previously-generated content, and can use that information to provide a much better prediction of a user's goals.
Further, sites like Twitter, StackOverflow, Google+, and Facebook support ways for the user to explicitly identify their precise goals when creating content: Hashtags.
These user-created hashtags are a key indicator to a user's goals on a social media site. 

These hashtags relate to a user's goals and interests because they are human-generated content, and a form of human-based document tagging \cite{Chang2010}.
Further, people are using hashtags as a way to create information streams on social media sites \parencite{Kwak2010}.
Twitter users, for example, commonly create hashtags for upcoming political events, such as debates and races \cite{Diakopoulos2010}.
So if we can predict what hashtags a user is interested in, we have a better understanding of the information streams that they care about.
With that understanding, we can tailor the system to suggest hashtags that they may not yet know about but are of likely interest to them.
We can help aid in their discovery of fresh and relevant information that match their goals on the site.

FIXME: It is certainly the case that real-time search on these social media sites is growing \parencite{Jansen2011}.

\subsection{Research Questions}

The core research question we are interested in is:
What kinds of cognitively-plausible models can best predict the human-generated tags that a user on a social media site is interested in?
This question can be tested by generating a prediction for the most likely used hashtag whenever a user is about to generate a hashtag, and then comparing the user's chosen hashtag to the model's prediction.
This process can be framed as a memory retrieval problem.
That is, each user on a social media site has created content that contain a set of human-generated tags within the context of each post.
The process of suggesting a relevant hashtag to a user can be thought of as a memory retrieval request for a hashtag, given prior hashtag use and current context.

Co-occurrence-based modeling has been shown as a potentially useful approach when predicting Twitter hashtag use \parencite{Efron2010}.
Several memory retrieval models are based on this broad methodology, where a count is maintained of the times each contextual element (such as a word in a post) co-occur with a tag.
Two of the current state-of-the-art memory models are based on a co-occurrence methodology, and we'll be comparing these two models for hashtag prediction:
ACT-R's declarative memory retrieval theory and random permutation vector-based memory systems.

\subsubsection{Comparison Between ACT-R and Vector-Based Memory Systems}

ACT-R's declarative memory and vector-based memory systems are substantially different in their implementation.
Nonetheless, both can successfully model the classic fan effect phenomena found in word pairing experiments \parencite{Rutledge2008}.
We will extend the work done by \textcite{Rutledge2008} by formally comparing the models on large-scale hashtag prediction tasks.
We'll also replace the vector-based model used by \textcite{Rutledge2008} with an improved and simplified random-permutation model \parencite{Sahlgren2008}.
The primary objective is to compare the random-permutation vector-based model to ACT-R's declarative memory theory.

An advantage of vector-based models is that word order can be easily incorporated into the single co-occurrence representation \parencite{Jones2007}.
Word-order information on sites like Twitter may contain highly-predictive pieces of information, as it is likely that specific words immediately precede specific hashtags.
However, it is unclear and unexplored how word order can be represented in the ACT-R declarative memory theory.
We will explore how the word-order strength of vector-based models can be incorporated into the ACT-R theory when testing the models on hashtag prediction tasks.

ACT-R's declarative memory system has a strong theory on how a user's prior knowledge and experience influences the likelihood that a particular memory item is retrieved \parencite{Anderson2004}.
However, it is unexplored how a user's prior knowledge should influence retrieval for vector-based models.
We will explore how a user's prior knowledge influences the likelihood that a particular hashtag is generated for both ACT-R's memory theory and vector-based models.

\subsubsection{Lifetime of a Hashtag for a Specific User}

Prior research has examined the growth and decay cycle of hashtag use across users \parencite{Tsur2012}.
However, much less is known about hashtag lifetime within a single user.
It may not be the case that a hashtag's lifecycle for a single user matches the lifecycle across users.
Further, modeling a hashtag's life within users is much more applicable to hashtag prediction, since that model can be directly incorporated into the a specific user's prior likelihood of hashtag use.
So we will characterize the hashtag growth and decay cycle within users.
The expectation is that this cycle will match ACT-R's decay rate used in the declarative memory system to compute a particular memory item's prior.

\subsubsection{User-Customized Hashtag Prediction}

The end goal of this work is to identify a memory retrieval model that can suggest relevant hashtags to users when they wish to retrieve one.
These hashtags should be customized to their specific interests and relevant to the content of the post that they are currently creating.
This will undoubtably require a combination of two primary model components:
[1] A user's prior likelihood of choosing a particular hashtag, given their prievously-generated content, [2] the likelihood that a particular hashtag is related to the context of the post being generated. 

***

TODO: How is recency information about the hashtag included in the model?

\subsubsection{StackOverflow and Twitter Task Domains}

TODO: StackOverflow and Twitter; large scale, hashtag prediction, etc. 

\section{Prior Research}

\subsection{Recommendation Systems}

Grown in need with the growth of the web.
Users on a site need access to specific pieces of information, and the site contains much more information than they can process / care about.
Recommendation systems are used to tailor the presented information to what is relevant to the user.
\cite{Pazzani2007}

\subsubsection{The Netflix Prize}

FIXME: Fix cite for Bennett2007
TODO: Summarize and \cite{Bennett2007}

\subsubsection{Recommending Followers on Twitter}

TODO: Summarize and \cite{Hannon2010}

\subsubsection{Hashtags for Recommendation Systems}

\cite{Efron2010} Generated related hashtags from 'query'.
Showed that users found those hashtags useful for the query.
Not using the model to predict hashtags from tweets, but a model like this could be used for that purpose.
They were focused more on making the case that hashtags provide useful information that can be used on sites like Twitter as part of a general recommendation system.

\subsection{Hashtag Prediction}

Previous research focused on StackOverflow, Google+, and Twitter.
Google+ has deployed automatic tagging of posts.

\subsubsection{StackOverflow}

TODO: \cite{Kuo2011}
FIXME: cite recent paper
FIXME: cite tex.stackexchange.org as a hashtag suggestion tool

\subsubsection{Google+}

TODO: Summarize Google+ hashtag prediction \cite{GoogleKeynote2013}

\subsubsection{Twitter}

TODO: None that we are aware of.

\subsection{ACT-R Declarative Memory Theory}

\cite{Anderson2004}

\subsubsection{ACT-R DM Model}

\subsubsection{Connection to Pointwise Mutual Information}

TODO: Introduce PMI \cite{Farahat2004}

TODO: Comparison to ACT-R: Virtually equivalent for large corpora \cite{Farahat2004}

\subsubsection{Scaling the Equations}

\cite{Douglass2010}

TODO: SNIF-ACT \cite{Fu2007} \cite{Pirolli2003}

\subsection{Latent Semantic Analysis Memory Theory}

TODO: Summarize \cite{Landauer1997}

\subsubsection{Singular Value Decomposition}

\subsubsection{Word Order}

\subsubsection{Scaling Issues}

TODO: Compare with PMI, performance and issue of scale. \cite{Budiu2007}

\subsection{Vector-Based Memory Systems}

TODO: Summarize \cite{Plate1995}

\subsubsection{Addressing Word Order}

\subsubsection{Addressing Scalability}

\subsubsection{BEAGLE}

TODO: Sumarize Jones' model \cite{Jones2007}

\subsubsection{Random Permutations}

TODO: Summarize \cite{Sahlgren2008}

\subsubsection{Comparison between BEAGLE and Random Permutations}

TODO: Summarize \cite{Recchia2010}

\subsubsection{Connection to LSA}

TODO: Summarize \cite{Kanerva2000}

\subsection{Comparison of Vector-Based Models and ACT-R}

TODO: Summarize MALTA \cite{Rutledge2007}

TODO: This approach can be used to model the fan effect \cite{Rutledge2008} 

TODO: However, there are open issues that need to be addressed:
TODO: Can user prior be represented in vector-based memory systems?
TODO: Can word order be represented in ACT-R?
TODO: Do they both scale?

\subsection{Incorporating Hashtag Recency}

\subsubsection{ACT-R}

TODO: ACT-R has a strong theory here.
TODO: IR literature for Twitter domain uses a model similar to ACT-R \cite{Efron2011}

\subsubsection{Vector-Based Models}

TODO: Unclear how recency will fit in with random permutation vector-based model.

\section{Methods}

\subsection{StackOverflow Dataset}

\cite{DataDump2013}

\subsection{Twitter Dataset}

TODO: common-hashtags dataset
TODO: popular-users dataset

\subsection{Tokenizing and Lemmetizing Text}

TODO: Python NLP toolkit \cite{Bird2009}

\subsection{Stop Words and Entropy Weighting}

TODO: Explore entropy weighting instead of stop word removal \cite{Dumais1991}

\subsection{Experiments}

\subsubsection{StackOverflow Dataset Modifications}

TODO: Use newest dataset
TODO: Chunk tags

\subsubsection{Analyze Recency for User-Generated Hashtags}

TODO: Use stackoverflow and twitter popular-users dataset

\subsubsection{Incorporating Recency Into Random Permutations}

TODO: Use stackoverflow dataset only for random permutations

\subsubsection{Incorporating Word Order Into ACT-R}

TODO: Use twitter common-hashtags dataset only for ACT-R

\subsubsection{Top Hashtag Prediction}

TODO: vector-based and act-r head to head on twitter common-hashtags
TODO: head to head without word order on twitter common-hashtags
TODO: head to head on stackoverflow

\subsubsection{User-Customized Hashtag Prediction}

TODO: head to head on twitter popular-users dataset
TODO: head to head on stackoverflow

\begingroup
\setstretch{1}
\setlength\bibitemsep{12pt}
\printbibliography
\endgroup

\end{document}

