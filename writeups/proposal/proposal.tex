\documentclass[man]{apa6}


\usepackage[american]{babel}
\usepackage[utf8]{inputenc}
%\usepackage[compact]{titlesec}

\usepackage{amssymb,amsmath}

\usepackage{graphicx}
\usepackage[group-separator={,}]{siunitx}
\RequirePackage[l2tabu, orthodox]{nag}
\graphicspath{{./figures/}} % Specifies the directory where pictures are stored

\usepackage{csquotes}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{bibliography.bib}

% If the toc is too detailed, try limiting the depth of printed sections in the TOC:
% \setcounter{tocdepth}{2}

\title{Psyc 601 Multivariate Statistics Project}
\shorttitle{Psyc 601 Project}

\author{Clayton Stanley}
\affiliation{Rice University}

\leftheader{Beitzel}

\abstract{
  The base StackOverflow tag-prediction model from the Fall '12 Psychometrics course was improved by incorporating the words in the body of the post and the post author's specific tagging history.
  We focused on hashtag creation as a specific human behavior, since understanding and modeling hashtag creation can lead to improved human-computer systems that can better identify users' goals and interests.
  We used multivariate logistic regression statistical techniques to guide the model building process, and found that adding the two model terms improved model accuracy from 56\% to 69\%.
  The model is a successful case showing that ACT-R's declarative memory retrieval equations scale, and are relevant to task domains that require large-scale knowledge stores.
}


\keywords{StackOverflow, Machine Learning, ACT-R, Tagging, Large-Scale Semantic Memory}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Motivation}

TODO: Motivation

TODO: Identifying user's goals when searching social media sites is an open research problem \cite{Rose2004}

TODO: Researchers are currently looking for ways to automate the task \cite{Lee2005}, \cite{Jansen2008}

TODO: Hashtags are an additional view of a user's goals when generating content on a site, and can help in this automation.
TODO: These hashtags relate to user's goals and interests because they are human-generated content; a form of human-based document tagging \cite{Chang2010}
TODO: People are also using hashtags as an information source on social media cites \cite{Diakopoulos2010} \cite{Kwak2010}

TODO: Natural question to ask is how can we build human-computer systems that help connect users to these hashtag information sources.

TODO: Co-occurence-based modeling is a potentially useful approach. \cite{Efron2010}

TODO: Challenging domain due to time constraints on information. \cite{Bauer2012}

TODO: Useful problem since real-time search on social media sites is growing \cite{Jansen2011}

\subsection{Research Questions}

\subsubsection{Comparison Between ACT-R and Vector-Based Memory Systems}

TODO: Extending work from \cite{Rutledge2008}

TODO: Can user prior be represented in vector-based memory systems?

TODO: Can word order be represented in ACT-R?

\subsubsection{Single-User-Focused Hashtag Modeling}

TODO: Comparison to global lifetime of a hashtag \cite{Tsur2012}

TODO: How is recency information about the hashtag included in the model?

\subsubsection{Task Domain}

TODO: StackOverflow and Twitter; large scale, hashtag prediction, etc. 

\section{Prior Research}

\subsection{Hashtag Prediction}

\subsubsection{StackOverflow}

TODO: \cite{Kuo2011}

\subsubsection{Google+}

TODO: Summarize Google+ hashtag prediction \cite{GoogleKeynote2013}

\subsubsection{Twitter}

\cite{Efron2010} Generated related hashtags from 'query'.
Showed that users found those hashtags useful for the query.
Not using the model to predict hashtags from tweets, but a model like this could be used for that purpose.
They were focused more on making the case that hashtags provide useful information that can be used on sites like Twitter as part of a general recommendation system.

\subsection{Recommendation Systems}

\subsubsection{The Netflix Prize}

TODO: Summarize and \cite{Bennett2007}

\subsubsection{Recommending Twitter Users to Follow}

TODO: Summarize and \cite{Hannon2010}

FIXME: Find cites for recommendation systems.

\section{ACT-R Declarative Memory Theory}

\cite{Anderson2004}

\subsection{ACT-R DM Model}

\subsection{Connection to Pointwise Mutual Information}

TODO: Introduce PMI \cite{Farahat2004}

TODO: Comparison to ACT-R: Virtually equivalent for large corpora \cite{Farahat2004}

\subsection{Scaling the Equations}

\cite{Douglass2010}

TODO: SNIF-ACT \cite{Fu2007} \cite{Pirolli2003}

\section{Latent Semantic Analysis Memory Theory}

TODO: Summarize \cite{Landauer1997}

\subsection{Singular Value Decomposition}

\subsection{Word Order}

\subsection{Scaling Issues}

TODO: Compare with PMI, performance and issue of scale. \cite{Budiu2007}

\section{Vector-Based Memory Systems}

TODO: Summarize \cite{Plate1995}

\subsection{Addressing Word Order}

\subsection{Addressing Scalability}

\subsection{BEAGLE}

TODO: Sumarize Jones' model \cite{Jones2007}

\subsection{Random Permutations}

TODO: Summarize \cite{Sahlgren2008}

\subsection{Comparison between BEAGLE and Random Permutations}

TODO: Summarize \cite{Recchia2010}

\subsection{Connection to LSA}

TODO: Summarize \cite{Kanerva2000}

\section{Comparison of Vector-based Models and ACT-R}

TODO: Summarize \cite{Rutledge2007}

TODO: This approach can be used to model the fan effect \cite{Rutledge2008} 

TODO: However, there are open issues that need to be addressed:
TODO: Can user prior be represented in vector-based memory systems?
TODO: Can word order be represented in ACT-R?
TODO: Do they both scale?

\section{Incorporating Hashtag Recency}

\subsection{ACT-R}

TODO: ACT-R has a strong theory here.
TODO: IR literature for Twitter domain uses a model similar to ACT-R \cite{Efron2011}

\subsection{Vector-based Models}

TODO: Unclear how recency will fit in with random permutation vector-based model.

\section{Methods}

\subsection{StackOverflow Dataset}

\cite{DataDump2013}

\subsection{Twitter Dataset}

TODO: common-hashtags dataset
TODO: popular-users dataset

\subsection{Tokenizing and Lemmetizing Text}

TODO: Python NLP toolkit \cite{Bird2009}

\subsection{Stop Words and Entropy Weighting}

TODO: Explore entropy weighting instead of stop word removal \cite{Dumais1991}

\subsection{Analyses}

\subsubsection{StackOverflow Dataset Modifications}

TODO: Use newest dataset
TODO: Chunk tags

\subsubsection{Analyze Recency for User-Generated Hashtags}

TODO: Use stackoverflow and twitter dataset

\subsubsection{Incorporating Recency Into Random Permutations}

TODO: Use stackoverflow dataset only for random permutations

\subsubsection{Incorporating Word Order Into ACT-R}

TODO: Use twitter dataset only for ACT-R

\subsubsection{Top Hashtag Prediction}

TODO: vector-based and act-r head to head on twitter
TODO: head to head on stackoverflow

\subsubsection{User-customized Hashtag Prediction}

\printbibliography

\end{document}

