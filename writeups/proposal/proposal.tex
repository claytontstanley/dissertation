\documentclass[man]{apa6}

\usepackage{textcomp}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}

%\usepackage[compact]{titlesec}

\usepackage{amssymb,amsmath}
\usepackage{setspace}

\usepackage[hyphens]{url}
%\usepackage{hyperref}
%\usepackage{breakurl}

\usepackage{graphicx}
\usepackage[group-separator={,}]{siunitx}
\RequirePackage[l2tabu, orthodox]{nag}
\graphicspath{{./figures/}} % Specifies the directory where pictures are stored

\usepackage{csquotes}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber,doi=false,uniquename=false]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{bibliography.bib}

% Needed to ensure periods are placed at the end of every bibliography entry in the references section
\AtEveryBibitem{\clearfield{doi}}

% Make sure only urls that are printed in references section are for webpages
\AtEveryBibitem{
  \ifentrytype{misc}{}{
    \clearfield{url}
  }
}

% ref: http://tex.stackexchange.com/questions/128592/remove-backslashes-from-url-fields-in-bib-entry
\DeclareSourcemap{
  \maps[datatype=bibtex]{
    \map{
      \step[fieldsource=url,
	match=\regexp{\\},
      replace=\regexp{}]
    }
  }
}


% If the toc is too detailed, try limiting the depth of printed sections in the TOC:
%\setcounter{tocdepth}{2}

\title{Psyc 601 Multivariate Statistics Project}
\shorttitle{Psyc 601 Project}

\author{Clayton Stanley}
\affiliation{Rice University}

\leftheader{Beitzel}

\abstract{
  The base StackOverflow tag-prediction model from the Fall '12 Psychometrics course was improved by incorporating the words in the body of the post and the post author's specific tagging history.
  We focused on hashtag creation as a specific human behavior, since understanding and modeling hashtag creation can lead to improved human-computer systems that can better identify users' goals and interests.
  We used multivariate logistic regression statistical techniques to guide the model building process, and found that adding the two model terms improved model accuracy from 56\% to 69\%.
  The model is a successful case showing that ACT-R's declarative memory retrieval equations scale, and are relevant to task domains that require large-scale knowledge stores.
}

\keywords{StackOverflow, Machine Learning, ACT-R, Tagging, Large-Scale Semantic Memory}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Motivation}

TODO: Motivation

Social media sites such as Twitter, Facebook, StackOverflow, Google+, and Yelp, are composed almost entirely of human-generated content.
The amount of human-generated content on these sites is staggering, and continues to grow.
Users of Twitter's microblogging service, for example, generate half a billion tweets per day \parencite{TwitterReport2012}.
However, a single user of a social media site is most likely interested in only a small fragment of this large amount of information.
One general question to support the the user in this domain is:
How can we quickly and effectively connect users to the content that they care about?

% FIXME: Fix cite for Bauer2012
One traditional technique is to provide the user with a powerful search engine so that they can actively look for content that interests them.
However, users are not forming the same search queries that work so effectively on search engines like Google.
Users of social media sites are searching for information that is happening now, in real time \cite{Bauer2012}.
In other words, users on social-media sites want the fresh \emph{stream} of information about a particular topic.
This can certainly be seen in the main user-interface views that these social media site provide:
Twitter's homepage showing your followers' tweets, Facebook's homepage showing your friends' posts, StackOverflow's daily digest of posts for particular tags, etc.

So how can we ensure that users are connected to the information streams that they care most about?
One promising approach is to model and predict the user's goals when using and searching these social media sites \parencite{Rose2004}.
If we have a better understanding of a user's goals, then we can tailor the information streams provided to the ones that are most inline with these goals.
For example, Twitter might suggest other users and hashtags for the user to follow, Facebook could suggest pages to like, Yelp could recommend businesses to check out, etc.
Researchers are currently looking for ways to automate the goal-identification task for more general search queries like those generated for Google \parencites{Jansen2008}{Lee2005}.

However, social media sites have an advantage for identifying user goals over traditional search engines:
Human-generated content.
Twitter does not have only the tweet that a user is currently composing to try and identify that user's goals.
Rather, the site has all of the user's previously-generated content, and can use that information to provide a much better prediction of a user's goals.
Further, sites like Twitter, StackOverflow, Google+, and Facebook support ways for the user to explicitly identify their precise goals when creating content: Hashtags.
These user-created hashtags are a key indicator to a user's goals on a social media site. 

These hashtags relate to a user's goals and interests because they are human-generated content, and a form of human-based document tagging \cite{Chang2010}.
Further, people are using hashtags as a way to create information streams on social media sites \parencite{Kwak2010}.
Twitter users, for example, commonly create hashtags for upcoming political events, such as debates and races \cite{Diakopoulos2010}.
So if we can predict what hashtags a user is interested in, we have a better understanding of the information streams that they care about.
With that understanding, we can tailor the system to suggest hashtags that they may not yet know about but are of likely interest to them.
We can help aid in their discovery of fresh and relevant information that match their goals on the site.

FIXME: It is certainly the case that real-time search on these social media sites is growing \parencite{Jansen2011}.

\subsection{Research Questions}

The core research question we are interested in is:
What kinds of cognitively-plausible models can best predict the human-generated tags that a user on a social media site is interested in?
This question can be tested by generating a prediction for the most likely used hashtag whenever a user is about to generate a hashtag, and then comparing the user's chosen hashtag to the model's prediction.
This process can be framed as a memory retrieval problem.
That is, each user on a social media site has created content that contain a set of human-generated tags within the context of each post.
The process of suggesting a relevant hashtag to a user can be thought of as a memory retrieval request for a hashtag, given prior hashtag use and current context.

Co-occurrence-based modeling has been shown as a potentially useful approach when predicting Twitter hashtag use \parencite{Efron2010}.
Several memory retrieval models are based on this broad methodology, where a count is maintained of the times each contextual element (such as a word in a post) co-occur with a tag.
Two of the current state-of-the-art memory models are based on a co-occurrence methodology, and we'll be comparing these two models for hashtag prediction:
ACT-R's declarative memory retrieval theory and random permutation vector-based memory systems.

\subsubsection{StackOverflow and Twitter Task Domains}

We will compare these two memory systems across two domains where users generate tags for posts: Twitter and StackOverflow.
Twitter is a micro-blogging service where users create 140 character tweets and broadcast those messages out to the users who follow their posts.
StackOverflow is a question and answer site for computer programming where users ask programming-related questions and fellow members of the community provide answers.

These two datasets were chosen because the content of the human-generated content is quite different between them, and we are interested in retrieval models that generalize across different task domains.
However, they are also quite similar on several accounts:
both domains have emassed large amounts of user-generated content, users generate tags for posts when creating content on the site, and the user data from the datasets are publicly available for analysis.

Also, studying user-based tag generation on these sites is a relevant task domain.
Models that can accuratly predict the tags that users will generate on Twitter and StackOverflow can be used as the foundation for recommendations systems on these very popular sites.
These systems can help newer users by recommending proper tags for their newest content.
On the StackOverflow site for example, experts often subscribe to specific hashtags that interest them, and receive a daily digest of posts that are tagged with those hashtags.
Helping the user properly tag posts on StackOverflow ensures that right community sees the post, which greatly increases the chance that the question on the post will be answered quickly and correctly.
For Twitter, hashtags represent streams of information that are possibly interesting to the user.
Having a recommendation system that can suggest relevant hashtags to the user provides a way for the user to connect to and discover new information streams.

\subsubsection{Comparison Between ACT-R and Vector-Based Memory Systems}

ACT-R's declarative memory and vector-based memory systems are substantially different in their implementation.
Nonetheless, both can successfully model the classic fan effect phenomena found in word pairing experiments \parencite{Rutledge2008}.
We will extend the work done by \textcite{Rutledge2008} by formally comparing the models on large-scale hashtag prediction tasks.
We'll also replace the vector-based model used by \textcite{Rutledge2008} with an improved and simplified random-permutation model \parencite{Sahlgren2008}.
The primary objective is to compare the random-permutation vector-based model to ACT-R's declarative memory theory.

An advantage of vector-based models is that word order can be easily incorporated into the single co-occurrence representation \parencite{Jones2007}.
Word-order information on sites like Twitter may contain highly-predictive pieces of information, as it is likely that specific words immediately precede specific hashtags.
However, it is unclear and unexplored how word order can be represented in the ACT-R declarative memory theory.
We will explore how the word-order strength of vector-based models can be incorporated into the ACT-R theory when testing the models on hashtag prediction tasks.

ACT-R's declarative memory system has a strong theory on how a user's prior knowledge and experience influences the likelihood that a particular memory item is retrieved \parencite{Anderson2004}.
However, it is unexplored how a user's prior knowledge should influence retrieval for vector-based models.
We will explore how a user's prior knowledge influences the likelihood that a particular hashtag is generated for both ACT-R's memory theory and vector-based models.

\subsubsection{Lifetime of a Hashtag for a Specific User}

Prior research has examined the growth and decay cycle of hashtag use across users \parencite{Tsur2012}.
However, much less is known about hashtag lifetime within a single user.
It may not be the case that a hashtag's lifecycle for a single user matches the lifecycle across users.
Further, modeling a hashtag's life within users is much more applicable to hashtag prediction, since that model can be directly incorporated into the a specific user's prior likelihood of hashtag use.
So we will characterize the hashtag growth and decay cycle within users.
The expectation is that this cycle will match ACT-R's decay rate used in the declarative memory system to compute a particular memory item's prior.
This decay rate equation formalizes how recency and frequency of hashtag use relate to the prior probability that a hashtag will be retrieved.

\subsubsection{User-Customized Hashtag Prediction}

The end goal of this work is to identify a memory retrieval model that can suggest relevant hashtags to users when they wish to retrieve one.
These hashtags should be customized to their specific interests and relevant to the content of the post that they are currently creating.
This will undoubtably require a combination of two primary model components:
[1] A user's prior likelihood of choosing a particular hashtag, given their prievously-generated content, and [2] the likelihood that a particular hashtag is related to the context of the post being generated. 

A user's prior hashtag use will be an essential model component for domains such as Twitter, where the number of possible hashtags is practically infinite.
In these domains, the model can utilize a user's prior hashtag use as a way to prune the infinite space of possible hashtags, and generate a much smaller and more manageable set for prediction.
However, not only should the model properly take into account a user's prior hashtag use, but it should also generate new hashtag predictions when a user is most likely choosing a hashtag they have never used before.
Calibrating the models to properly balance this exploitation of prior hashtag use vs. exploration of new hashtags will be a primary resaerch focus.
The end goal is to have a model that can properly balance the user's prior tag with the contextual cues in the post in order to generate an accurate prediciton.

\section{Prior Research}

\subsection{Recommendation Systems}

A model that predicts a user-chosen hashtag is a specific type of the more general recommendatino systems.
These systems have grown in need with the growth of the web.
Users on a site need quick access to specific pieces of information, and the site contains much more information than they can process or care about.
Recommendation systems are used to tailor the information presented to what is most relevant to the user \cite{Pazzani2007}.

\subsubsection{The Netflix Prize}

% FIXME: Fix cite for Bennett2007
The Netflix Prize \parencite{Bennett2007} is an example of a recommendation system where prior user behavior and current context was used to present the most relevant information to the user.
Netflix is an online-subscription service where users can stream their favorite television episodes and movies.
Each user of the site is only interested in a small portion of the entire library of content that Netflix provides.
In order to provide a high-quality user experience on the site, Netflix created a content-recommendation service.
This tool recommends to the user movies and television episodes that most likely match their specific interests.
Netflix wanted to improve the accuracy of their recommendation system, so they held a competition where teams could try to improve on the accuracy of the service.

The winning team utilized a singular value decomposition (SVD) method to identify particular dimensions of the entire content library (e.g., genre, time period, previously watched) that best predicted user preferences.
This is a dimensionality-reducing technique that aims to filter out noise by forcing the data to be represented from a smaller number of dimensions than were originally present.
This method used prior user behavior to classify a user along the dimensions of the reduced space, and current user behavior (e.g., just watched) to understand what they were interested in watching at that moment.
By using an SVD technique and combining these indicators, the model improved on Netflix's original recommendation system by 10\%.

\subsubsection{Recommending Followers on Twitter}

Recommendation systems based on the content of user-generated posts have been successfull in recommending people on Twitter for a user to follow.
\parencite{Hannon2010} built a Twitter follower recommendation system by creating a profile of each user based on the words they used in previous posts.
The recommendation system would then suggest other Twitter users to follow that had similar profiles to a particular user.
The profiles were created by generating a word frequency matrix of words x (user + followers + followees), and then providing that matrix as input into the Lucine text search engine framework.
When the system needed to recommend a set of individuals for a user to follow, it would take all of the words used in posts from that user to construct a search query to be provided to Lucine.
That search query would return the most likely users that share similar words in posts within their twitter network with the words provided in the query.
Using this simple technique based on a standard text search engine allowed the recommendation system to accurately predict the people that a particular user will follow at 25\% accuracy.

\subsubsection{Hashtags for Recommendation Systems}

\cite{Efron2010} showed how hashtags might be used as a type of recommendation system for Twitter.
Users constructed a query of text that represented a search for a topic that they were interested in.
The system then retrieved the most likely hashtags that were associated with that search query.
The model is based on building a word co-occurance matrix of words x hashtags, and then uses that matrix to assign a similarity score for each hashtag when provided with a search query.
Participants graded how relevant the hashtags returned were to each search query.
The results suggest that hashtags contain useful information that help classify the gist of a post. 
Although this model does not predict hashtags directly when composing a tweet, a model like this could certainly be tailored for that purpose.

\subsection{Hashtag Prediction}

Previous research focused on StackOverflow, Google+, and Twitter.
Google+ has deployed automatic tagging of posts.

\subsubsection{StackOverflow}

TODO: \cite{Kuo2011}
FIXME: cite recent paper
FIXME: cite tex.stackexchange.org as a hashtag suggestion tool

\subsubsection{Google+}

TODO: Summarize Google+ hashtag prediction \cite{GoogleKeynote2013}

\subsubsection{Twitter}

TODO: None that we are aware of.

\subsection{ACT-R Declarative Memory Theory}

\cite{Anderson2004}

\subsubsection{ACT-R DM Model}

\subsubsection{Connection to Pointwise Mutual Information}

TODO: Introduce PMI \cite{Farahat2004}

TODO: Comparison to ACT-R: Virtually equivalent for large corpora \cite{Farahat2004}

\subsubsection{Scaling the Equations}

\cite{Douglass2010}

TODO: SNIF-ACT \cite{Fu2007} \cite{Pirolli2003}

\subsection{Latent Semantic Analysis Memory Theory}

TODO: Summarize \cite{Landauer1997}

\subsubsection{Singular Value Decomposition}

\subsubsection{Word Order}

\subsubsection{Scaling Issues}

TODO: Compare with PMI, performance and issue of scale. \cite{Budiu2007}

\subsection{Vector-Based Memory Systems}

TODO: Summarize \cite{Plate1995}

\subsubsection{Addressing Word Order}

\subsubsection{Addressing Scalability}

\subsubsection{BEAGLE}

TODO: Sumarize Jones' model \cite{Jones2007}

\subsubsection{Random Permutations}

TODO: Summarize \cite{Sahlgren2008}

\subsubsection{Comparison between BEAGLE and Random Permutations}

TODO: Summarize \cite{Recchia2010}

\subsubsection{Connection to LSA}

TODO: Summarize \cite{Kanerva2000}

\subsection{Comparison of Vector-Based Models and ACT-R}

TODO: Summarize MALTA \cite{Rutledge2007}

TODO: This approach can be used to model the fan effect \cite{Rutledge2008} 

TODO: However, there are open issues that need to be addressed:
TODO: Can user prior be represented in vector-based memory systems?
TODO: Can word order be represented in ACT-R?
TODO: Do they both scale?

\subsection{Incorporating Hashtag Recency}

\subsubsection{ACT-R}

TODO: ACT-R has a strong theory here.
TODO: IR literature for Twitter domain uses a model similar to ACT-R \cite{Efron2011}

\subsubsection{Vector-Based Models}

TODO: Unclear how recency will fit in with random permutation vector-based model.

\section{Models}

TODO: Formal description of each model.

\section{Methods}

\subsection{StackOverflow Dataset}

\cite{DataDump2013}

\subsection{Twitter Dataset}

TODO: common-hashtags dataset
TODO: popular-users dataset

\subsection{Tokenizing and Lemmetizing Text}

TODO: Python NLP toolkit \cite{Bird2009}

\subsection{Stop Words and Entropy Weighting}

TODO: Explore entropy weighting instead of stop word removal \cite{Dumais1991}

\subsection{Experiments}

\subsubsection{StackOverflow Dataset Modifications}

TODO: Use newest dataset
TODO: Chunk tags

\subsubsection{Analyze Recency for User-Generated Hashtags}

TODO: Use stackoverflow and twitter popular-users dataset

\subsubsection{Incorporating Recency Into Random Permutations}

TODO: Use stackoverflow dataset only for random permutations

\subsubsection{Incorporating Word Order Into ACT-R}

TODO: Use twitter common-hashtags dataset only for ACT-R

\subsubsection{Top Hashtag Prediction}

TODO: vector-based and act-r head to head on twitter common-hashtags
TODO: head to head without word order on twitter common-hashtags
TODO: head to head on stackoverflow

\subsubsection{User-Customized Hashtag Prediction}

TODO: head to head on twitter popular-users dataset
TODO: head to head on stackoverflow

\begingroup
\setstretch{1}
\setlength\bibitemsep{12pt}
\printbibliography
\endgroup

\end{document}

