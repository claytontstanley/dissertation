\documentclass[man]{apa6}

\usepackage{textcomp}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}
%\usepackage[compact]{titlesec}

\usepackage{amssymb,amsmath}
\usepackage{setspace}

\usepackage[hyphens]{url}
%\usepackage{hyperref}
%\usepackage{breakurl}

\usepackage{graphicx}
\usepackage[group-separator={,}]{siunitx}
\RequirePackage[l2tabu, orthodox]{nag}
\graphicspath{{./figures/}} % Specifies the directory where pictures are stored

\usepackage{csquotes}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber,doi=false,uniquename=false]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{bibliography.bib}

% If the toc is too detailed, try limiting the depth of printed sections in the TOC:
%\setcounter{tocdepth}{2}

\title{Psyc 601 Multivariate Statistics Project}
\shorttitle{Psyc 601 Project}

\author{Clayton Stanley}
\affiliation{Rice University}

\leftheader{Beitzel}

\abstract{
  The base StackOverflow tag-prediction model from the Fall '12 Psychometrics course was improved by incorporating the words in the body of the post and the post author's specific tagging history.
  We focused on hashtag creation as a specific human behavior, since understanding and modeling hashtag creation can lead to improved human-computer systems that can better identify users' goals and interests.
  We used multivariate logistic regression statistical techniques to guide the model building process, and found that adding the two model terms improved model accuracy from 56\% to 69\%.
  The model is a successful case showing that ACT-R's declarative memory retrieval equations scale, and are relevant to task domains that require large-scale knowledge stores.
}

\keywords{StackOverflow, Machine Learning, ACT-R, Tagging, Large-Scale Semantic Memory}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Motivation}

TODO: Motivation

TODO: Useful problem since real-time search on social media sites is growing \cite{Jansen2011}
TODO: Social media sites are composed almost entirely of human-generated content.
Users are searching through this content.
TODO: Users want to be quickly connected to the content that they care about, with minimal amount of searching necessary, since the amount of generated content on these sites is so vast.

TODO: Challenging domain due to time constraints on information. \cite{Bauer2012}

TODO: Identifying user's goals when searching social media sites is an open research problem \cite{Rose2004}

TODO: Researchers are currently looking for ways to automate the task \cite{Lee2005}, \cite{Jansen2008}

TODO: Hashtags are an additional view of a user's goals when generating content on a site, and can help in this automation.
TODO: These hashtags relate to user's goals and interests because they are human-generated content; a form of human-based document tagging \cite{Chang2010}
TODO: People are also using hashtags as an information source on social media cites \cite{Diakopoulos2010} \cite{Kwak2010}

TODO: Natural question to ask is if we can predict a users' interested hashtags, we have a better understanding of that user's goals on the site.
And with that understanding, we can improve their interaction with the site by tailoring the system to give them content that they care most about.

TODO: Co-occurence-based modeling is a potentially useful approach. \cite{Efron2010}

\subsection{Research Questions}

\subsubsection{Comparison Between ACT-R and Vector-Based Memory Systems}

TODO: Extending work from \cite{Rutledge2008}

TODO: Can user prior be represented in vector-based memory systems?

TODO: Can word order be represented in ACT-R?

\subsubsection{Modeling Hashtag Use for a Single User}

TODO: Comparison to global lifetime of a hashtag \cite{Tsur2012}

TODO: How is recency information about the hashtag included in the model?

\subsubsection{Adding Word-Order Information When Predicting Hashtags}

TODO: speak generally about how word order might be useful for hashtags

\subsubsection{StackOverflow and Twitter Task Domains}

TODO: StackOverflow and Twitter; large scale, hashtag prediction, etc. 

\section{Prior Research}

\subsection{Recommendation Systems}

Grown in need with the growth of the web.
Users on a site need access to specific pieces of information, and the site contains much more information than they can process / care about.
Recommendation systems are used to tailor the presented information to what is relevant to the user.
\cite{Pazzani2007}

\subsubsection{The Netflix Prize}

TODO: Summarize and \cite{Bennett2007}

\subsubsection{Recommending Followers on Twitter}

TODO: Summarize and \cite{Hannon2010}

\subsubsection{Hashtags for Recommendation Systems}

\cite{Efron2010} Generated related hashtags from 'query'.
Showed that users found those hashtags useful for the query.
Not using the model to predict hashtags from tweets, but a model like this could be used for that purpose.
They were focused more on making the case that hashtags provide useful information that can be used on sites like Twitter as part of a general recommendation system.

\subsection{Hashtag Prediction}

Previous research focused on StackOverflow, Google+, and Twitter.
Google+ has deployed automatic tagging of posts.

\subsubsection{StackOverflow}

TODO: \cite{Kuo2011}

\subsubsection{Google+}

TODO: Summarize Google+ hashtag prediction \cite{GoogleKeynote2013}

\subsubsection{Twitter}

TODO: None that we are aware of.

\subsection{ACT-R Declarative Memory Theory}

\cite{Anderson2004}

\subsubsection{ACT-R DM Model}

\subsubsection{Connection to Pointwise Mutual Information}

TODO: Introduce PMI \cite{Farahat2004}

TODO: Comparison to ACT-R: Virtually equivalent for large corpora \cite{Farahat2004}

\subsubsection{Scaling the Equations}

\cite{Douglass2010}

TODO: SNIF-ACT \cite{Fu2007} \cite{Pirolli2003}

\subsection{Latent Semantic Analysis Memory Theory}

TODO: Summarize \cite{Landauer1997}

\subsubsection{Singular Value Decomposition}

\subsubsection{Word Order}

\subsubsection{Scaling Issues}

TODO: Compare with PMI, performance and issue of scale. \cite{Budiu2007}

\subsection{Vector-Based Memory Systems}

TODO: Summarize \cite{Plate1995}

\subsubsection{Addressing Word Order}

\subsubsection{Addressing Scalability}

\subsubsection{BEAGLE}

TODO: Sumarize Jones' model \cite{Jones2007}

\subsubsection{Random Permutations}

TODO: Summarize \cite{Sahlgren2008}

\subsubsection{Comparison between BEAGLE and Random Permutations}

TODO: Summarize \cite{Recchia2010}

\subsubsection{Connection to LSA}

TODO: Summarize \cite{Kanerva2000}

\subsection{Comparison of Vector-Based Models and ACT-R}

TODO: Summarize MALTA \cite{Rutledge2007}

TODO: This approach can be used to model the fan effect \cite{Rutledge2008} 

TODO: However, there are open issues that need to be addressed:
TODO: Can user prior be represented in vector-based memory systems?
TODO: Can word order be represented in ACT-R?
TODO: Do they both scale?

\subsection{Incorporating Hashtag Recency}

\subsubsection{ACT-R}

TODO: ACT-R has a strong theory here.
TODO: IR literature for Twitter domain uses a model similar to ACT-R \cite{Efron2011}

\subsubsection{Vector-Based Models}

TODO: Unclear how recency will fit in with random permutation vector-based model.

\section{Methods}

\subsection{StackOverflow Dataset}

\cite{DataDump2013}

\subsection{Twitter Dataset}

TODO: common-hashtags dataset
TODO: popular-users dataset

\subsection{Tokenizing and Lemmetizing Text}

TODO: Python NLP toolkit \cite{Bird2009}

\subsection{Stop Words and Entropy Weighting}

TODO: Explore entropy weighting instead of stop word removal \cite{Dumais1991}

\subsection{Experiments}

\subsubsection{StackOverflow Dataset Modifications}

TODO: Use newest dataset
TODO: Chunk tags

\subsubsection{Analyze Recency for User-Generated Hashtags}

TODO: Use stackoverflow and twitter popular-users dataset

\subsubsection{Incorporating Recency Into Random Permutations}

TODO: Use stackoverflow dataset only for random permutations

\subsubsection{Incorporating Word Order Into ACT-R}

TODO: Use twitter common-hashtags dataset only for ACT-R

\subsubsection{Top Hashtag Prediction}

TODO: vector-based and act-r head to head on twitter common-hashtags
TODO: head to head without word order on twitter common-hashtags
TODO: head to head on stackoverflow

\subsubsection{User-Customized Hashtag Prediction}

TODO: head to head on twitter popular-users dataset
TODO: head to head on stackoverflow

\begingroup
\setstretch{1}
\setlength\bibitemsep{12pt}
\printbibliography
\endgroup

\end{document}

